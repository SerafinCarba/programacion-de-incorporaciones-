{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio de programación de incorporaciones .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "copyright-notice",
        "mNCLhxsXyOIS",
        "eQS5KQzBybTY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerafinCarba/programacion-de-incorporaciones-/blob/master/Ejercicio_de_programaci%C3%B3n_de_incorporaciones_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright-notice"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "copyright-notice2",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTaAdgy3LS8W",
        "colab_type": "text"
      },
      "source": [
        " # Introducción a los datos dispersos y las incorporaciones\n",
        "\n",
        "**Objetivos de aprendizaje:**\n",
        "* convertir datos de strings de reseñas de películas en un vector de atributos dispersos\n",
        "* implementar un modelo lineal de análisis de opiniones a través de un vector de atributos dispersos\n",
        "* implementar un modelo de RNP de análisis de opiniones a través de una incorporación que proyecte datos en dos dimensiones\n",
        "* visualizar la incorporación para observar qué aprendió el modelo acerca de las relaciones entre las palabras\n",
        "\n",
        "En este ejercicio, exploraremos datos dispersos y trabajaremos con incorporaciones mediante el uso de datos de texto de reseñas de películas (del [conjunto de datos de IMDB de ACL 2011](http://ai.stanford.edu/~amaas/data/sentiment/). Estos datos ya se procesaron en formato `tf.Example`.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKGtmwNosU8",
        "colab_type": "text"
      },
      "source": [
        " ## Preparación\n",
        "\n",
        "Importemos nuestras dependencias y descarguemos los datos de entrenamiento y de prueba. [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) incluye una herramienta de almacenamiento en caché y descarga de archivos que podemos usar para recuperar los conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWqDqFFL_NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W7aZ9qspZVj",
        "colab_type": "text"
      },
      "source": [
        " ## Desarrollo de un modelo de análisis de opiniones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jieA0k_NLS8a",
        "colab_type": "text"
      },
      "source": [
        " Entrenemos un modelo de análisis de opiniones con estos datos, que prediga si una reseña es en general *favorable* (etiqueta de 1) o *desfavorable* (etiqueta de 0).\n",
        "\n",
        "Para eso, convertiremos nuestros `terms` con valores de strings en vectores de atributos a través de un *vocabulario*, una lista de cada término que esperamos ver en nuestros datos. Para los fines de este ejercicio, creamos un pequeño vocabulario que se enfoca en un conjunto de términos limitado. La mayoría de estos se consideraron fuertes indicadores de *favorable* o *unfavorable*, pero algunos se agregaron simplemente porque son interesantes.\n",
        "\n",
        "Cada término del vocabulario está asignado a una coordenada de nuestro vector de atributos. Para convertir los `terms` con valores de strings para un ejemplo en este formato de vector, los codificamos de manera tal que cada coordenada obtenga un valor de 0 si el término del vocabulario no aparece en la string de ejemplo y un valor de 1 si aparece. Los términos de un ejemplo que no aparecen en el vocabulario se descartan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HSfklfnLS8b",
        "colab_type": "text"
      },
      "source": [
        " **NOTA:** *Desde luego, podríamos usar un vocabulario más grande. También existen herramientas especiales para crearlos. Además, en lugar de simplemente descartar los términos que no están en el vocabulario, podemos incorporar una pequeña cantidad de agrupamientos OOV (fuera de vocabulario), con los cuales se puede generar un hash para los términos que no están en el vocabulario. A su vez, podemos usar un enfoque de __generación de hashes de atributos__ que genere hashes de cada término, en lugar de crear un vocabulario explícito. Esto funciona bien en la práctica, pero dificulta la interpretabilidad, que es útil para este ejercicio. Consulta el módulo tf.feature_column para obtener herramientas para abordar esto.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvoa2HyDtgqe",
        "colab_type": "text"
      },
      "source": [
        " ## Desarrollo de la canalización de entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O20vMEOurDol",
        "colab_type": "text"
      },
      "source": [
        " Primero, configuremos la canalización de entrada para importar nuestros datos a un modelo de TensorFlow. Podemos usar la siguiente función para analizar los datos de entrenamiento y de prueba (que se encuentran en formato [TFRecord](https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data)) y devolver un diccionario de los atributos y etiquetas correspondientes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxNIEniPq2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return  {'terms':terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXhTeeYMrp-l",
        "colab_type": "text"
      },
      "source": [
        " Para confirmar que nuestra función se desempeña de acuerdo con lo esperado, construyamos un `TFRecordDataset` para los datos de entrenamiento y asignemos los datos a atributos y etiquetas a través del atributo que se incluyó más arriba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF4YWXR0Omt0",
        "colab_type": "code",
        "outputId": "9a4ace6d-814e-45b1-aa8d-bc262b2b2586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)\n",
        "\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUoMvK-9tVXP",
        "colab_type": "text"
      },
      "source": [
        " Ejecuta la siguiente celda para recuperar el primer ejemplo del conjunto de datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6QE2DWRUc4E",
        "colab_type": "code",
        "outputId": "5d61b8f2-59c6-4c36-be65-550eeff9786f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()\n",
        "sess.run(n)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'terms': array([b'but', b'it', b'does', b'have', b'some', b'good', b'action',\n",
              "         b'and', b'a', b'plot', b'that', b'is', b'somewhat', b'interesting',\n",
              "         b'.', b'nevsky', b'acts', b'like', b'a', b'body', b'builder',\n",
              "         b'and', b'he', b'isn', b\"'\", b't', b'all', b'that', b'attractive',\n",
              "         b',', b'in', b'fact', b',', b'imo', b',', b'he', b'is', b'ugly',\n",
              "         b'.', b'(', b'his', b'acting', b'skills', b'lack', b'everything',\n",
              "         b'!', b')', b'sascha', b'is', b'played', b'very', b'well', b'by',\n",
              "         b'joanna', b'pacula', b',', b'but', b'she', b'needed', b'more',\n",
              "         b'lines', b'than', b'she', b'was', b'given', b',', b'her',\n",
              "         b'character', b'needed', b'to', b'be', b'developed', b'.',\n",
              "         b'there', b'are', b'way', b'too', b'many', b'men', b'in', b'this',\n",
              "         b'story', b',', b'there', b'is', b'zero', b'romance', b',', b'too',\n",
              "         b'much', b'action', b',', b'and', b'way', b'too', b'dumb', b'of',\n",
              "         b'an', b'ending', b'.', b'it', b'is', b'very', b'violent', b'.',\n",
              "         b'i', b'did', b'however', b'love', b'the', b'scenery', b',',\n",
              "         b'this', b'movie', b'takes', b'you', b'all', b'over', b'the',\n",
              "         b'world', b',', b'and', b'that', b'is', b'a', b'bonus', b'.', b'i',\n",
              "         b'also', b'liked', b'how', b'it', b'had', b'some', b'stuff',\n",
              "         b'about', b'the', b'mafia', b'in', b'it', b',', b'not', b'too',\n",
              "         b'much', b'or', b'too', b'little', b',', b'but', b'enough',\n",
              "         b'that', b'it', b'got', b'my', b'attention', b'.', b'the',\n",
              "         b'actors', b'needed', b'to', b'be', b'more', b'handsome', b'.',\n",
              "         b'.', b'.', b'the', b'biggest', b'problem', b'i', b'had', b'was',\n",
              "         b'that', b'nevsky', b'was', b'just', b'too', b'normal', b',',\n",
              "         b'not', b'sexy', b'enough', b'.', b'i', b'think', b'for', b'most',\n",
              "         b'guys', b',', b'sascha', b'will', b'be', b'hot', b'enough', b',',\n",
              "         b'but', b'for', b'us', b'ladies', b'that', b'are', b'fans', b'of',\n",
              "         b'action', b',', b'nevsky', b'just', b'doesn', b\"'\", b't', b'cut',\n",
              "         b'it', b'.', b'overall', b',', b'this', b'movie', b'was', b'fine',\n",
              "         b',', b'i', b'didn', b\"'\", b't', b'love', b'it', b'nor', b'did',\n",
              "         b'i', b'hate', b'it', b',', b'just', b'found', b'it', b'to', b'be',\n",
              "         b'another', b'normal', b'action', b'flick', b'.'], dtype=object)},\n",
              " array([0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBU39UeFty9S",
        "colab_type": "text"
      },
      "source": [
        " Ahora, desarrollemos una función de entrada formal que podamos pasar al método `train()` de un objeto de Estimator de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_C5-ueNYIn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input_fn that parses the tf.Examples from the given files,\n",
        "# and split them into features and targets.\n",
        "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
        "  \n",
        "  # Same code as above; create a dataset and map features and labels.\n",
        "  ds = tf.data.TFRecordDataset(input_filenames)\n",
        "  ds = ds.map(_parse_function)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(10000)\n",
        "\n",
        "  # Our feature data is variable-length, so we pad and batch\n",
        "  # each field of the dataset structure to whatever size is necessary.     \n",
        "  ds = ds.padded_batch(25, ds.output_shapes)\n",
        "  \n",
        "  ds = ds.repeat(num_epochs)\n",
        "\n",
        "  \n",
        "  # Return the next batch of data.\n",
        "  features, labels = ds.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y170tVlrLS8c",
        "colab_type": "text"
      },
      "source": [
        " ## Tarea 1: Usar un modelo lineal con entradas dispersas y vocabulario explícito\n",
        "\n",
        "Para nuestro primer modelo, desarrollaremos un modelo de [`LinearClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) con 50 términos informativos; siempre debemos comenzar por lo más simple.\n",
        "\n",
        "El siguiente código genera la columna de atributos para nuestros términos. El atributo [`categorical_column_with_vocabulary_list`](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list) crea una columna de funciones con la asignación de string a vector de funciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5gdxuWsvPcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 50 informative terms that compose our model vocabulary. \n",
        "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
        "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
        "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
        "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
        "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
        "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
        "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
        "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
        "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
        "                     \"drama\", \"family\")\n",
        "\n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTiDwyorwd3P",
        "colab_type": "text"
      },
      "source": [
        " A continuación, generaremos el `LinearClassifier`, lo entrenaremos con el conjunto de entrenamiento y lo evaluaremos con el conjunto de evaluación. Después de leer todo el código, ejecútalo y observa el desempeño."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYKKpGLqLS8d",
        "colab_type": "code",
        "outputId": "bf48e13b-4475-4b84-811a-be544ce156db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "feature_columns = [ terms_feature_column ]\n",
        "\n",
        "\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  optimizer=my_optimizer,\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.78876\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8718128\n",
            "auc_precision_recall 0.8626489\n",
            "average_loss 0.45086613\n",
            "label/mean 0.5\n",
            "loss 11.271653\n",
            "precision 0.7631406\n",
            "prediction/mean 0.5071384\n",
            "recall 0.83744\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.7838\n",
            "accuracy_baseline 0.5\n",
            "auc 0.86987597\n",
            "auc_precision_recall 0.86030877\n",
            "average_loss 0.45201382\n",
            "label/mean 0.5\n",
            "loss 11.300345\n",
            "precision 0.75979495\n",
            "prediction/mean 0.50543594\n",
            "recall 0.83\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ubn9gULS8g",
        "colab_type": "text"
      },
      "source": [
        " ## Tarea 2: Usar un modelo de redes neuronales profundas (RNP)\n",
        "\n",
        "El modelo anterior es un modelo lineal que funciona bastante bien. Pero, ¿podemos obtener un mejor desempeño con un modelo de RNP?\n",
        "\n",
        "Cambiemos a un [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) en lugar del `LinearClassifier`. Ejecuta la siguiente celda y observa qué desempeño obtienes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcgOPfEALS8h",
        "colab_type": "code",
        "outputId": "f87402c7-2fcc-4ebd-b622-6a23b42b4c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "##################### Here's what we changed ##################################\n",
        "classifier = tf.estimator.DNNClassifier(                                      #\n",
        "  feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], #\n",
        "  hidden_units=[20,20],                                                       #\n",
        "  optimizer=my_optimizer,                                                     #\n",
        ")                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "try:\n",
        "  classifier.train(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1000)\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([train_path]),\n",
        "    steps=1)\n",
        "  print(\"Training set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "\n",
        "  evaluation_metrics = classifier.evaluate(\n",
        "    input_fn=lambda: _input_fn([test_path]),\n",
        "    steps=1)\n",
        "\n",
        "  print(\"Test set metrics:\")\n",
        "  for m in evaluation_metrics:\n",
        "    print(m, evaluation_metrics[m])\n",
        "  print(\"---\")\n",
        "except ValueError as err:\n",
        "  print(err)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.76\n",
            "accuracy_baseline 0.64\n",
            "auc 0.9374999\n",
            "auc_precision_recall 0.96455777\n",
            "average_loss 0.37442017\n",
            "label/mean 0.64\n",
            "loss 9.360504\n",
            "precision 0.9166667\n",
            "prediction/mean 0.5024548\n",
            "recall 0.6875\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.92\n",
            "accuracy_baseline 0.52\n",
            "auc 0.99999994\n",
            "auc_precision_recall 0.9999999\n",
            "average_loss 0.22010092\n",
            "label/mean 0.48\n",
            "loss 5.502523\n",
            "precision 0.85714287\n",
            "prediction/mean 0.49469692\n",
            "recall 1.0\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZz68luxLS8j",
        "colab_type": "text"
      },
      "source": [
        " ## Tarea 3: Usar una incorporación con un modelo de RNP\n",
        "\n",
        "En esta tarea, implementaremos nuestro modelo de RNP mediante el uso de una columna de incorporaciones. Una columna de incorporaciones toma datos dispersos como entrada y devuelve un vector denso de dimensiones más bajas como resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliRzhvJLS8k",
        "colab_type": "text"
      },
      "source": [
        " **NOTA:** *Una embedding_column suele ser la opción más eficaz con relación al cómputo que se puede usar para entrenar un modelo con datos dispersos. En una [sección opcional](#scrollTo=XDMlGgRfKSVz) al final de este ejercicio, analizaremos en más detalle las diferencias de implementación entre el uso de una `embedding_column` y una `indicator_column`, así como las ventajas y desventajas de seleccionar una o la otra.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-as3PtALS8l",
        "colab_type": "text"
      },
      "source": [
        " En el siguiente código, realiza lo siguiente:\n",
        "\n",
        "* Define las columnas de atributos para el modelo a través de una `embedding_column` que proyecte los datos en 2 dimensiones (para obtener más detalles sobre la firma de funciones para `embedding_column`, consulta la [documentación de TF](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column)).\n",
        "* Define un `DNNClassifier` con las siguientes especificaciones:\n",
        "  * Dos capas ocultas de 20 unidades cada una\n",
        "  * Optimización de AdaGrad con una tasa de aprendizaje de 0.1\n",
        "  * Una `gradient_clip_norm` de 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlPZ-Q9bLS8m",
        "colab_type": "text"
      },
      "source": [
        " **NOTA:** *En la práctica, es posible que proyectemos en más que 2 dimensiones, como 50 o 100. Pero, por ahora, 2 dimensiones son fáciles de visualizar.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNCLhxsXyOIS",
        "colab_type": "text"
      },
      "source": [
        " ### Sugerencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L67xYD7hLS8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's a example code snippet you might use to define the feature columns:\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv1UBsJxyV37",
        "colab_type": "text"
      },
      "source": [
        " ### Completa el código a continuación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PG_yhNGLS8u",
        "colab_type": "code",
        "outputId": "1a088e32-49e8-4696-ee06-dcc17e6a9478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "########################## YOUR CODE HERE ######################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "\n",
        "################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.787\n",
            "accuracy_baseline 0.5\n",
            "auc 0.8687801\n",
            "auc_precision_recall 0.85734653\n",
            "average_loss 0.45379445\n",
            "label/mean 0.5\n",
            "loss 11.344861\n",
            "precision 0.7602844\n",
            "prediction/mean 0.5216456\n",
            "recall 0.83832\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.78484\n",
            "accuracy_baseline 0.5\n",
            "auc 0.86787605\n",
            "auc_precision_recall 0.8555139\n",
            "average_loss 0.45518923\n",
            "label/mean 0.5\n",
            "loss 11.37973\n",
            "precision 0.76017535\n",
            "prediction/mean 0.52049893\n",
            "recall 0.83224\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQS5KQzBybTY",
        "colab_type": "text"
      },
      "source": [
        " ### Solución\n",
        "\n",
        "Haz clic más abajo para conocer la solución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xOdYeQydi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## SOLUTION CODE ########################################\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[20,20],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "#################################################################################\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHnnVtzLS8w",
        "colab_type": "text"
      },
      "source": [
        " ## Tarea 4: Convencerte de que realmente hay una incorporación allí\n",
        "\n",
        "El modelo anterior utilizó una `embedding_column` y pareció tener un buen desempeño, pero esto no nos indica mucho qué ocurre internamente. ¿Cómo podemos comprobar que el modelo realmente está usando una incorporación dentro?\n",
        "\n",
        "Para comenzar, observemos los tensores del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1jNgLdQLS8w",
        "colab_type": "code",
        "outputId": "2eb68747-2945-4866-ee27-367a85393f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "classifier.get_variable_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dnn/hiddenlayer_0/bias',\n",
              " 'dnn/hiddenlayer_0/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_0/kernel',\n",
              " 'dnn/hiddenlayer_0/kernel/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/bias',\n",
              " 'dnn/hiddenlayer_1/bias/t_0/Adagrad',\n",
              " 'dnn/hiddenlayer_1/kernel',\n",
              " 'dnn/hiddenlayer_1/kernel/t_0/Adagrad',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights',\n",
              " 'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights/t_0/Adagrad',\n",
              " 'dnn/logits/bias',\n",
              " 'dnn/logits/bias/t_0/Adagrad',\n",
              " 'dnn/logits/kernel',\n",
              " 'dnn/logits/kernel/t_0/Adagrad',\n",
              " 'global_step']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl4-VctMLS8z",
        "colab_type": "text"
      },
      "source": [
        " Bien, podemos observar que hay una capa de incorporaciones allí: `'dnn/input_from_feature_columns/input_layer/terms_embedding/...'`. (De hecho, lo interesante aquí es que esta capa se puede entrenar junto con el resto del modelo, al igual que cualquier capa oculta).\n",
        "\n",
        "¿La capa de incorporaciones tiene la forma correcta? Ejecuta el siguiente código para descubrirlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFxyQUiLS80",
        "colab_type": "text"
      },
      "source": [
        " **NOTA:** *Recuerda que, en nuestro caso, la incorporación es una matriz que nos permite proyectar un vector de 50 dimensiones en 2 dimensiones.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xMbpcEjLS80",
        "colab_type": "code",
        "outputId": "a881cb9b-7813-4e91-e123-a9de59f914e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights').shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLCIogjLS82",
        "colab_type": "text"
      },
      "source": [
        " Dedica un tiempo a comprobar manualmente las diferentes capas y formas a fin de asegurarte de que todo esté conectado según lo esperado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkKAaRWDLS83",
        "colab_type": "text"
      },
      "source": [
        " ## Tarea 5: Examinar la incorporación\n",
        "\n",
        "Ahora observemos el espacio de incorporación real y veamos dónde acaban los términos dentro de este. Realiza lo siguiente:\n",
        "1. Ejecuta el código que aparece a continuación para ver la incorporación que entrenamos en la **Tarea 3**. ¿Los términos están donde esperabas?\n",
        "\n",
        "2. Ejecutar el código de la **Tarea 3** otra vez para volver a entrenar el modelo y, luego, vuelve a ejecutar la visualización de la incorporación que aparece más abajo. ¿Qué permanece igual? ¿Qué cambia?\n",
        "\n",
        "3. Finalmente, vuelve a entrenar el modelo con solo 10 pasos (lo cual producirá un modelo terrible). Vuelve a ejecutar la visualización de la incorporación que aparece más abajo. ¿Qué ves ahora y por qué?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4NNu7KqLS84",
        "colab_type": "code",
        "outputId": "dfab2bc9-fc2c-4053-c660-c2b34aa038b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "embedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')\n",
        "\n",
        "for term_index in range(len(informative_terms)):\n",
        "  # Create a one-hot encoding for our term.  It has 0s everywhere, except for\n",
        "  # a single 1 in the coordinate that corresponds to that term.\n",
        "  term_vector = np.zeros(len(informative_terms))\n",
        "  term_vector[term_index] = 1\n",
        "  # We'll now project that one-hot vector into the embedding space.\n",
        "  embedding_xy = np.matmul(term_vector, embedding_matrix)\n",
        "  plt.text(embedding_xy[0],\n",
        "           embedding_xy[1],\n",
        "           informative_terms[term_index])\n",
        "\n",
        "# Do a little setup to make sure the plot displays nicely.\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
        "plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2kAAANOCAYAAACLIUQoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGDHSJEmSJClG/h9KI0WTSDqmngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUb3L7pqLS86",
        "colab_type": "text"
      },
      "source": [
        " ## Tarea 6: Intentar mejorar el rendimiento del modelo\n",
        "\n",
        "Ve si puedes ajustar el modelo para mejorar el rendimiento. A continuación, se indican algunas acciones que puedes probar:\n",
        "\n",
        "* **Cambiar los hiperparámetros** o **usar un optimizador diferente**, como Adam (es posible que solo ganes uno o dos puntos en el porcentaje de exactitud con estas estrategias).\n",
        "* **Agregar términos adicionales a `informative_terms`.** Hay un archivo de vocabulario completo con los 30,716 términos para este conjunto de datos que puedes usar en https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt. Puedes seleccionar términos adicionales de este archivo de vocabulario o usar el archivo completo a través de la columna de atributos `categorical_column_with_vocabulary_file`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-b3BqXvLS86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the vocabulary file.\n",
        "terms_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt'\n",
        "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbJlwW5LS8-",
        "colab_type": "code",
        "outputId": "87d65f84-24b1-4ee8-ac06-44dc7c1b9a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "# Create a feature column from \"terms\", using a full vocabulary file.\n",
        "informative_terms = None\n",
        "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
        "  # Convert it to a set first to remove duplicates.\n",
        "  informative_terms = list(set(f.read().split()))\n",
        "  \n",
        "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", \n",
        "                                                                                 vocabulary_list=informative_terms)\n",
        "\n",
        "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)\n",
        "feature_columns = [ terms_embedding_column ]\n",
        "\n",
        "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "  feature_columns=feature_columns,\n",
        "  hidden_units=[10,10],\n",
        "  optimizer=my_optimizer\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([train_path]),\n",
        "  steps=1000)\n",
        "print(\"Training set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")\n",
        "\n",
        "evaluation_metrics = classifier.evaluate(\n",
        "  input_fn=lambda: _input_fn([test_path]),\n",
        "  steps=1000)\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "for m in evaluation_metrics:\n",
        "  print(m, evaluation_metrics[m])\n",
        "print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set metrics:\n",
            "accuracy 0.82868\n",
            "accuracy_baseline 0.5\n",
            "auc 0.9047747\n",
            "auc_precision_recall 0.9015274\n",
            "average_loss 0.3924855\n",
            "label/mean 0.5\n",
            "loss 9.812138\n",
            "precision 0.8271359\n",
            "prediction/mean 0.50346386\n",
            "recall 0.83104\n",
            "global_step 1000\n",
            "---\n",
            "Test set metrics:\n",
            "accuracy 0.81316\n",
            "accuracy_baseline 0.5\n",
            "auc 0.89116323\n",
            "auc_precision_recall 0.8876822\n",
            "average_loss 0.4174576\n",
            "label/mean 0.5\n",
            "loss 10.43644\n",
            "precision 0.8160678\n",
            "prediction/mean 0.50052893\n",
            "recall 0.80856\n",
            "global_step 1000\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew3kwGM-LS9B",
        "colab_type": "text"
      },
      "source": [
        " ## Conclusión\n",
        "\n",
        "Es posible que hayamos obtenido una solución de RNP con una incorporación que se desempeñó mejor que nuestro modelo lineal original, pero el modelo lineal también era bastante bueno y algo más rápido para entrenar. Los modelos lineales se entrenan más rápidamente porque no tienen tantos parámetros para actualizar o capas para realizar propagación inversa.\n",
        "\n",
        "En algunas aplicaciones, la velocidad de los modelos lineales puede cambiar las reglas del juego. A veces, los modelos lineales pueden ser muy convenientes desde el punto de vista de la calidad. Y en otras áreas, la complejidad adicional del modelo y la capacidad proporcionada por las RNP puede ser más importante. Al definir la arquitectura del modelo, recuerda explorar tu problema lo suficiente como para saber en qué espacio te encuentras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MquXy9zLS9B",
        "colab_type": "text"
      },
      "source": [
        " ### *Análisis opcional:* Ventajas y desventajas entre `embedding_column` y `indicator_column`\n",
        "\n",
        "A nivel conceptual, cuando entrenamos un `LinearClassifier` o un `DNNClassifier`, necesitamos una adaptación para usar una columna dispersa. TF ofrece dos opciones: `embedding_column` o `indicator_column`.\n",
        "\n",
        "Al entrenar un clasificador lineal (como en la **Tarea 1**), se usa una `embedding_column` como opción avanzada. Como se ve en la **Tarea 2**, al entrenar un `DNNClassifier`, debes elegir explícitamente `embedding_column` o `indicator_column`. En esta sección, se observa un ejemplo simple para analizar la diferencia entre ambas, así como las ventajas y desventajas de usar una o la otra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_3XuZ_LLS9C",
        "colab_type": "text"
      },
      "source": [
        " Imagina que tenemos datos dispersos que contienen los valores `\"great\"`, `\"beautiful\"` y `\"excellent\"`. Dado que el tamaño del vocabulario que estamos usando aquí es de $V = 50$, cada unidad (neurona) de la primera capa tendrá 50 ponderaciones. Denotamos el número de términos de una entrada dispersa mediante el uso de $s$. Por lo tanto, para los datos dispersos de este ejemplo, $s = 3$. Para una capa de entrada con $V$ valores posibles, una capa oculta con $d$ unidades debe hacer una multiplicación de vector por matriz: $(1 \\times V) * (V \\times d)$. Esto tiene un costo de cómputo de $O(V * d)$. Ten en cuenta que este costo es proporcional al número de ponderaciones en una capa oculta e independiente de $s$.\n",
        "\n",
        "Si las entradas tienen codificación de un solo 1 (un vector booleano con una longitud de $V$ con un 1 para los términos presentes y un 0 para el resto) que usa una [`indicator_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column), esto significa multiplicar y sumar muchos ceros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7mR4Wa2LS9C",
        "colab_type": "text"
      },
      "source": [
        " Cuando logramos exactamente los mismos resultados al usar una [`embedding_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column) con un tamaño de $d$, buscamos y sumamos solamente aquellas incorporaciones correspondientes a las tres atributos presentes en la entrada de nuestro ejemplo de `\"great\"`, `\"beautiful\"` y `\"excellent\"`: $(1 \\times d) + (1 \\times d) + (1 \\times d)$. Dado que las ponderaciones de los atributos que están ausentes se multiplican por cero en la multiplicación de vector por matriz, estas no contribuyen al resultado. Las ponderaciones de los atributos que están presentes se multiplican por 1 en la multiplicación de vector por matriz. Por lo tanto, al sumar las ponderaciones obtenidas a través de la búsqueda de incorporaciones, se obtendrá el mismo resultado que en la multiplicación de vector por matriz.\n",
        "\n",
        "Al usar una incorporación, el cómputo de la búsqueda de incorporaciones es un cómputo de $O(s * d)$, el cual es mucho más eficiente con relación al cómputo que el costo de $O(V * d)$ para la `indicator_column` en datos dispersos, para los cuales $s$ es mucho más pequeño que $V$. (Recuerda que estas incorporaciones se están aprendiendo. En cualquier iteración de entrenamiento dada, las ponderaciones actuales son las que se buscan.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZ9qf0kLS9D",
        "colab_type": "text"
      },
      "source": [
        " Como vimos en la **Tarea 3**, al usar una `embedding_column` al entrenar el `DNNClassifier`, nuestro modelo aprende una representación de dimensiones bajas para los atributos, en la que el producto de puntos define una métrica de similitud adaptada a la tarea deseada. En este ejemplo, los términos que se usan de manera similar en el contexto de las reseñas de películas (p. ej., `\"great\"` y `\"excellent\"`) estarán más cerca entre sí en el espacio de incorporación (es decir, tendrán un producto de puntos de gran tamaño) y los términos que son desemejantes (p. ej., `\"great\"` y `\"bad\"`) estarán más alejados entre sí en el espacio de incorporación (es decir, tendrán un producto de puntos pequeño)."
      ]
    }
  ]
}